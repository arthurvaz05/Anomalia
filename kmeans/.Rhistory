source('/Users/arthurvaz/Desktop/CEFETRJ - Mestrado/Anomalia/Anomalia/carregar_bases.R')
#loading Harbinger
load_library("daltoolbox")
load_library("harbinger")
###LOAD AND INSTALL
{
# Library to load and install if ins't already installed
#install.packages('pacman')
library(pacman)
vetor_pacotes <- c("ggplot2", "plotly", "dplyr", "kableExtra", "gridExtra",
"TSPred", "dbscan", "fpc", "factoextra", "fitdistrplus",
"logspline", "caret","RColorBrewer")
pacman::p_load(char = vetor_pacotes)
load_library("daltoolbox")
load_library("harbinger")
}
install.packages("devtools")
###LOAD AND INSTALL
{
# Library to load and install if ins't already installed
#install.packages('pacman')
library(pacman)
vetor_pacotes <- c("ggplot2", "plotly", "dplyr", "kableExtra", "gridExtra",
"TSPred", "dbscan", "fpc", "factoextra", "fitdistrplus",
"logspline", "caret","RColorBrewer")
pacman::p_load(char = vetor_pacotes)
load_library("daltoolbox")
load_library("harbinger")
}
install.packages('pacman')
###LOAD AND INSTALL
{
# Library to load and install if ins't already installed
#install.packages('pacman')
library(pacman)
vetor_pacotes <- c("ggplot2", "plotly", "dplyr", "kableExtra", "gridExtra",
"TSPred", "dbscan", "fpc", "factoextra", "fitdistrplus",
"logspline", "caret","RColorBrewer")
pacman::p_load(char = vetor_pacotes)
load_library("daltoolbox")
load_library("harbinger")
}
load_library("daltoolbox")
load_library("harbinger")
install.packages("daltoolbox")
install.packages("harbinger")
library(daltoolbox)
library(harbinger)
# establishing kmeans method
model <- hanct_kmeans(3)
# establishing kmeans method
model <- hanct_kmeans(10)
#ploting serie #1
plot_ts(x = 1:length(dataset$serie), y = dataset$serie,
xlab = "Time", ylab = "Value", main = "Serie #1")
#ploting serie #1
plot_ts(x = 1:length(dataset$serie), y = dataset$serie)
dataset <- gecco_sample
dataset%>%columns()
dataset%>%colnames()
#ploting serie #1
plot_ts(x = 1:length(dataset[,serie]), y = dataset[,serie])
serie <- tp
serie <- 'tp'
#ploting serie #1
plot_ts(x = 1:length(dataset[,serie]), y = dataset[,serie])
# establishing kmeans method
model <- hanct_kmeans(10)
# fitting the model
model <- fit(model, dataset[,serie])
# making detections of discords using kmeans
detection <- detect(model, dataset$serie)
# making detections of discords using kmeans
detection <- detect(model, dataset[,serie])
# filtering detected events
print(detection |> dplyr::filter(event==TRUE))
# evaluating the detections
evaluation <- evaluate(model, detection[,event])
print(evaluation$confMatrix)
event <- 'event'
# evaluating the detections
evaluation <- evaluate(model, detection[,event])
print(evaluation$confMatrix)
detection[,event]
# evaluating the detections
evaluation <- evaluate(model, detection[,event])
print(evaluation$confMatrix)
detection
# filtering detected events
print(detection |> dplyr::filter(event==TRUE))
detection[,event]
detection[,event]%>%table()
dataset[,event]%>%table()
# ploting the results
grf <- har_plot(model, dataset[,event])
plot(grf)
model
# ploting the results
grf <- har_plot(model, dataset[,event])
# ploting the results
grf <- har_plot(model, dataset$event)
# ploting the results
grf <- har_plot(model,dataset[,serie],detection ,dataset[,event])
plot(grf)
# filtering detected events
print(detection |> dplyr::filter(event==TRUE))
# ploting the results
grf <- har_plot(model,dataset[,serie],detection ,dataset[,event],idx=800:850)
# ploting the results
grf <- har_plot(model,dataset[,serie],detection ,dataset[,event],idx=800)
plot(grf)
# ploting the results
grf <- har_plot(model,dataset[,serie],detection ,dataset[,event],idx=800:850)
# ploting the results
grf <- har_plot(model,dataset[,serie],detection ,dataset[,event],idx=range(800:850))
# ploting the results
grf <- har_plot(model,dataset[,serie],detection ,dataset[,event],idx=c(800,801))
# ploting the results
grf <- har_plot(model,dataset[,serie],detection ,dataset[,event],idx=[800,801])
# ploting the results
grf <- har_plot(model,dataset[,serie],detection ,dataset[,event],idx=822)
plot(grf)
# ploting the results
grf <- har_plot(model,dataset[,serie],detection ,dataset[,event],idx=823)
plot(grf)
# ploting the results
grf <- har_plot(model,dataset[,serie],detection ,dataset[,event],idx=821)
plot(grf)
# ploting the results
grf <- har_plot(model,dataset[,serie],detection ,dataset[,event],idx=801)
plot(grf)
# ploting the results
grf <- har_plot(model,dataset[,serie],detection ,dataset[,event],idx=701)
plot(grf)
# ploting the results
grf <- har_plot(model,dataset[,serie],detection ,dataset[,event])
plot(grf)
dataset[800:850,serie]
# ploting the results
grf <- har_plot(model,dataset[800:850,serie],detection ,dataset[800:850,event])
plot(grf)
# ploting the results
grf <- har_plot(model,dataset[,serie],detection ,dataset[,event])
plot(grf)
model
detection
model
model$har_outliers()
model$har_outliers(dataset[,serie])
model$har_outliers(detection)
dataset[,event]%>%table()
source('/Users/arthurvaz/Desktop/CEFETRJ - Mestrado/Anomalia/Anomalia/carregar_bases.R')
###LOAD AND INSTALL
{
# Library to load and install if ins't already installed
#install.packages('pacman')
library(pacman)
vetor_pacotes <- c("ggplot2", "plotly", "dplyr", "kableExtra", "gridExtra",
"TSPred", "dbscan", "fpc", "factoextra", "fitdistrplus",
"logspline", "caret","RColorBrewer")
pacman::p_load(char = vetor_pacotes)
library(daltoolbox)
library(harbinger)
}
dataset <- gecco_sample
dataset%>%colnames()
serie <- 'tp'
event <- 'event'
dataset[,event]%>%table()
#ploting serie #1
plot_ts(x = 1:length(dataset[,serie]), y = dataset[,serie])
# establishing kmeans method
model <- hanct_kmeans(5)
# fitting the model
model <- fit(model, dataset[,serie])
# making detections of discords using kmeans
detection <- detect(model, dataset[,serie])
# filtering detected events
print(detection |> dplyr::filter(event==TRUE))
detection[,event]%>%table()
detection
View(detection)
detection$event
detection |> dplyr::filter(event==TRUE)
seq_window <- detection |> dplyr::filter(event==TRUE)
seq_window
seq_window <- detection |> dplyr::filter(event==TRUE)
seq_window$idx
seq(1:seq_window$window[1])
seq_window$window[1]
seq(1:seq_window$window)
seq_window$window
seq(1:seq_window$seqlen)
seq(1:seq_window$seqlen)+seq_window$idx
seq_window$idx
seq(1:seq_window$seqlen)+(seq_window$idx-1)
View(dataset)
View(gecco_sample)
#loading the example database
data(har_examples)
#Using the time series 18
dataset <- har_examples$example18
head(dataset)
#Using the time series 18
dataset <- har_examples$example18
source("header.R")
library(daltoolbox)
library(harbinger)
#loading the example database
data(har_examples)
#Using the time series 18
dataset <- har_examples$example18
head(dataset)
#save the dataset as a csv file
write.csv(dataset, "dataset_test_kmeans_anomlies.csv", row.names = FALSE)
# read csv
dataset <- read.csv("/Users/arthurvaz/Desktop/NTS/Dados/pivoted_df.csv", header = TRUE, sep = ",")
head(dataset)
#ploting serie #1
plot_ts(x = 1:length(dataset$CNCO_GAS.analog.BM2gFQA.PI.curval_sm_ruido), y = dataset$CNCO_GAS.analog.BM2gFQA.PI.curval_norm_zscore)
source("header.R")
library(daltoolbox)
library(harbinger)
#loading the example database
data(har_examples)
#Using the time series 1
dataset <- har_examples[[5]]
head(dataset)
# read csv
dataset <- read.csv("/Users/arthurvaz/Desktop/NTS/Dados/pivoted_df.csv", header = TRUE, sep = ",")
head(dataset)
#ploting serie #1
plot_ts(x = 1:length(dataset$CNCO_GAS.analog.BM2gFQA.PI.curval_sm_ruido), y = dataset$CNCO_GAS.analog.BM2gFQA.PI.curval_norm_zscore)
# establishing change point method
model <- hcp_chow()
# fitting the model
model <- fit(model, dataset$CNCO_GAS.analog.BM2gFQA.PI.curval_norm_zscore)
# making detections using hanr_fbiad
detection <- detect(model, dataset$CNCO_GAS.analog.BM2gFQA.PI.curval_norm_zscore)
# filtering detected events
print(detection |> dplyr::filter(event==TRUE))
dataset[print(detection |> dplyr::filter(event==TRUE))$idx,]
dataset$Event <- as.factor(detection$event)
dataset$Event <- as.factor(detection$Event)
dataset$Event
# evaluating the detections
evaluation <- evaluate(model, detection$event, dataset$Event)
print(evaluation$confMatrix)
# evaluating the detections
evaluation <- evaluate(model, detection$event, dataset$Event)
# read csv
dataset <- read.csv("/Users/arthurvaz/Desktop/NTS/Dados/pivoted_df.csv", header = TRUE, sep = ",")
head(dataset)
#ploting serie #1
plot_ts(x = 1:length(dataset$CNCO_GAS.analog.BM2gFQA.PI.curval_sm_ruido), y = dataset$CNCO_GAS.analog.BM2gFQA.PI.curval_norm_zscore)
# establishing change point method
model <- hcp_chow()
# fitting the model
model <- fit(model, dataset$CNCO_GAS.analog.BM2gFQA.PI.curval_norm_zscore)
# making detections using hanr_fbiad
detection <- detect(model, dataset$CNCO_GAS.analog.BM2gFQA.PI.curval_norm_zscore)
# filtering detected events
print(detection |> dplyr::filter(event==TRUE))
dataset[print(detection |> dplyr::filter(event==TRUE))$idx,]
# read csv
dataset <- read.csv("/Users/arthurvaz/Desktop/NTS/Dados/pivoted_df.csv", header = TRUE, sep = ",")
head(dataset)
#ploting serie #1
plot_ts(x = 1:length(dataset$CNCO_GAS.analog.BM2gFQA.PI.curval_sm_ruido), y = dataset$CNCO_GAS.analog.BM2gFQA.PI.curval_norm_zscore)
# establishing change point method
model <- hcp_chow()
# fitting the model
model <- fit(model, dataset$CNCO_GAS.analog.BM2gFQA.PI.curval_norm_zscore)
# making detections using hanr_fbiad
detection <- detect(model, dataset$CNCO_GAS.analog.BM2gFQA.PI.curval_norm_zscore)
# filtering detected events
print(detection |> dplyr::filter(event==TRUE))
# Base directory for the datasets
base_dir <- "/Users/arthurvaz/Desktop/CEFETRJ - Mestrado/Anomalia/Anomalia/Dataset"
# List of dataset filenames (without the base directory)
filenames <- c(
"gecco_sample.RData",
"nab_sample.RData",
"oil_3w_sample.RData",
"rare_sample.RData",
"ucr_sample.RData",
"yahoo_sample.RData"
)
load(file.path(base_dir,filenames[1]))
rm(df_final)
for (j in c(5, 10, 15, 20, 25, 30)) {
for (i in colnames(gecco_sample)[colnames(gecco_sample) != "event"]){
model <- hanct_kmeans(seq = j, centers = 2)
fitted_model <- fit(model, gecco_sample[,i])
detection <- detect(fitted_model, gecco_sample[,i])
seq_window <- detection %>% filter(event == TRUE)
seq_window <- seq_window %>% mutate(variable = i)
seq_window <- seq_window %>% mutate(dataset = "gecco_sample")
# evaluating the detections
evaluation <- evaluate(model, detection$event, gecco_sample[,'event'])
seq_window <- seq_window %>% mutate(recall = evaluation$recall)
seq_window <- seq_window %>% mutate(precision = evaluation$precision)
seq_window <- seq_window %>% mutate(F1 = evaluation$F1)
# conditional if df_final exists then rbind else create df_final
if(exists("df_final")){
df_final <- rbind(df_final, seq_window)
} else {
df_final <- seq_window
}
}
}
source('/Users/arthurvaz/Desktop/CEFETRJ - Mestrado/Anomalia/Anomalia/carregar_bases.R')
###LOAD AND INSTALL
{
# Library to load and install if ins't already installed
#install.packages('pacman')
library(pacman)
vetor_pacotes <- c("ggplot2", "plotly", "dplyr", "kableExtra", "gridExtra",
"TSPred", "dbscan", "fpc", "factoextra", "fitdistrplus",
"logspline", "caret","RColorBrewer","R.filesets")
pacman::p_load(char = vetor_pacotes)
library(daltoolbox)
library(harbinger)
setwd('/Users/arthurvaz/Desktop/CEFETRJ - Mestrado/Anomalia/Anomalia/kmeans')
source('kmeans_anomalia_windows.R')
}
# Base directory for the datasets
base_dir <- "/Users/arthurvaz/Desktop/CEFETRJ - Mestrado/Anomalia/Anomalia/Dataset"
# List of dataset filenames (without the base directory)
filenames <- c(
"gecco_sample.RData",
"nab_sample.RData",
"oil_3w_sample.RData",
"rare_sample.RData",
"ucr_sample.RData",
"yahoo_sample.RData"
)
load(file.path(base_dir,filenames[1]))
rm(df_final)
for (j in c(5, 10, 15, 20, 25, 30)) {
for (i in colnames(gecco_sample)[colnames(gecco_sample) != "event"]){
model <- hanct_kmeans(seq = j, centers = 2)
fitted_model <- fit(model, gecco_sample[,i])
detection <- detect(fitted_model, gecco_sample[,i])
seq_window <- detection %>% filter(event == TRUE)
seq_window <- seq_window %>% mutate(variable = i)
seq_window <- seq_window %>% mutate(dataset = "gecco_sample")
# evaluating the detections
evaluation <- evaluate(model, detection$event, gecco_sample[,'event'])
seq_window <- seq_window %>% mutate(recall = evaluation$recall)
seq_window <- seq_window %>% mutate(precision = evaluation$precision)
seq_window <- seq_window %>% mutate(F1 = evaluation$F1)
# conditional if df_final exists then rbind else create df_final
if(exists("df_final")){
df_final <- rbind(df_final, seq_window)
} else {
df_final <- seq_window
}
}
}
df_final
View(df_final)
View(df_final)
# Number of windows detected
df_final %>% group_by(variable) %>% summarise(n = n())
# Number of sizes of windows detected
df_final %>% group_by(seq) %>% summarise(n = n())
df_final
# Create the scatter plot
scatter_plot <- ggplot(df, aes(x = recall, y = precision, color = variable, shape = factor(seqlen))) +
geom_point() +
labs(x = "Recall", y = "Precision", color = "Variable", shape = "Seqlen") +
scale_shape_manual(values = c(1, 2, 3, 4, 5)) +  # Customize point shapes
theme_minimal()
# Create the scatter plot
scatter_plot <- ggplot(df_final, aes(x = recall, y = precision, color = variable, shape = factor(seqlen))) +
geom_point() +
labs(x = "Recall", y = "Precision", color = "Variable", shape = "Seqlen") +
scale_shape_manual(values = c(1, 2, 3, 4, 5)) +  # Customize point shapes
theme_minimal()
# Show the scatter plot
print(scatter_plot)
# Create the scatter plot using scale_shape_discrete
scatter_plot <- ggplot(df, aes(x = recall, y = precision, color = variable, shape = factor(seqlen))) +
geom_point() +
labs(x = "Recall", y = "Precision", color = "Variable", shape = "Seqlen") +
scale_shape_discrete() +  # Automatic shape assignment based on unique values
theme_minimal()
# Show the scatter plot
print(scatter_plot)
# Create a custom shape palette with enough values
custom_shape_palette <- c(16, 17, 18, 19, 20)  # You can choose different values
# Create the scatter plot using scale_shape_manual with the custom palette
scatter_plot <- ggplot(df, aes(x = recall, y = precision, color = variable, shape = factor(seqlen))) +
geom_point() +
labs(x = "Recall", y = "Precision", color = "Variable", shape = "Seqlen") +
scale_shape_manual(values = custom_shape_palette) +  # Use the custom shape palette
theme_minimal()
# Create a custom shape palette with enough values
# Create a custom shape palette with enough values
custom_shape_palette <- c(16, 17, 18, 19, 20)  # You can choose different values
# Create the scatter plot using scale_shape_manual with the custom palette
scatter_plot <- ggplot(df_final, aes(x = recall, y = precision, color = variable, shape = factor(seqlen))) +
geom_point() +
labs(x = "Recall", y = "Precision", color = "Variable", shape = "Seqlen") +
scale_shape_manual(values = custom_shape_palette) +  # Use the custom shape palette
theme_minimal()
# Show the scatter plot
print(scatter_plot)
# Create a scatter plot using scale_shape_continuous
scatter_plot <- ggplot(df_final, aes(x = recall, y = precision, color = variable, shape = as.numeric(seqlen))) +
geom_point() +
labs(x = "Recall", y = "Precision", color = "Variable", shape = "Seqlen") +
scale_shape_continuous(guide = guide_legend(override.aes = list(size = 4))) +
theme_minimal()
# Show the scatter plot
print(scatter_plot)
# Convert seqlen to a factor
df_final$seqlen <- factor(df_final$seqlen)
# Create a scatter plot using scale_shape_manual
scatter_plot <- ggplot(df_final, aes(x = recall, y = precision, color = variable, shape = seqlen)) +
geom_point() +
labs(x = "Recall", y = "Precision", color = "Variable", shape = "Seqlen") +
scale_shape_manual(values = c(16, 17, 18, 19, 20)) +  # Assign shapes manually
theme_minimal()
# Show the scatter plot
print(scatter_plot)
df <- df_final
# Convert seqlen to a factor
df$seqlen <- factor(df$seqlen)
# Check unique values in the seqlen variable
unique_seqlen <- unique(df$seqlen)
# Determine the number of unique seqlen values
num_unique_seqlen <- length(unique_seqlen)
# Create a scatter plot using scale_shape_manual
scatter_plot <- ggplot(df, aes(x = recall, y = precision, color = variable, shape = seqlen)) +
geom_point() +
labs(x = "Recall", y = "Precision", color = "Variable", shape = "Seqlen") +
scale_shape_manual(values = 1:num_unique_seqlen) +  # Assign shapes manually
theme_minimal()
# Show the scatter plot
print(scatter_plot)
# Create a scatter plot using scale_shape_manual
scatter_plot <- ggplot(df, aes(x = recall, y = precision, color = variable, shape = seqlen)) +
geom_point() +
labs(x = "Recall", y = "Precision", color = "Variable", shape = "Seqlen") +
scale_shape_manual(values = 1:num_unique_seqlen) +  # Assign shapes manually
ggtitle("Scatter Plot of Precision vs. Recall") +  # Add a title
theme_minimal()
# Show the scatter plot
print(scatter_plot)
# Create a scatter plot using scale_shape_manual
scatter_plot <- ggplot(df, aes(x = recall, y = precision, color = variable, shape = seqlen)) +
geom_point() +
labs(x = "Recall", y = "Precision", color = "Variable", shape = "Seqlen") +
scale_shape_manual(values = 1:num_unique_seqlen) +  # Assign shapes manually
ggtitle("Gecco Kmeans result: Precision vs. Recall") +  # Add a title
theme_minimal()
# Show the scatter plot
print(scatter_plot)
# Average recall and precision by variable
df_final %>% group_by(variable) %>% summarise(mean_recall = mean(recall), mean_precision = mean(precision))
# Average recall and precision by size
df_final %>% group_by(seq) %>% summarise(mean_recall = mean(recall), mean_precision = mean(precision))
# Number of windows detected sorted by variable
df_final %>% group_by(variable) %>% summarise(n = n())
# Number of windows detected sorted by variable
df_final %>% group_by(variable) %>% summarise(n = n()) %>% arrange(desc(n))
# Number of sizes of windows detected
df_final %>% group_by(seq) %>% summarise(n = n()) %>% arrange(desc(n))
# Average recall and precision by variable
df_final %>% group_by(variable) %>% summarise(mean_recall = mean(recall), mean_precision = mean(precision)) %>% arrange(desc(mean_recall))
# Average recall and precision by size
df_final %>% group_by(seq) %>% summarise(mean_recall = mean(recall), mean_precision = mean(precision)) %>% arrange(desc(mean_precision))
# Number of windows detected sorted by variable
df_final %>% group_by(variable) %>% summarise(n = n()) %>% arrange(desc(n))
# Number of sizes of windows detected
df_final %>% group_by(seq) %>% summarise(n = n()) %>% arrange(desc(n))
# Average recall and precision by variable
df_final %>% group_by(variable) %>% summarise(mean_recall = mean(recall), mean_precision = mean(precision)) %>% arrange(desc(mean_precision))
# Average recall and precision by size
df_final %>% group_by(seq) %>% summarise(mean_recall = mean(recall), mean_precision = mean(precision)) %>% arrange(desc(mean_precision))
# Convert seqlen to a factor
df_final$seqlen <- factor(df_final$seqlen)
# Check unique values in the seqlen variable
unique_seqlen <- unique(df_final$seqlen)
# Determine the number of unique seqlen values
num_unique_seqlen <- length(unique_seqlen)
# Create a scatter plot using scale_shape_manual
scatter_plot <- ggplot(df_final, aes(x = recall, y = precision, color = variable, shape = seqlen)) +
geom_point() +
labs(x = "Recall", y = "Precision", color = "Variable", shape = "Seqlen") +
scale_shape_manual(values = 1:num_unique_seqlen) +  # Assign shapes manually
ggtitle("Gecco Kmeans result: Precision vs. Recall") +  # Add a title
theme_minimal()
# Show the scatter plot
print(scatter_plot)
# Number of windows detected sorted by variable
df_final %>% group_by(variable) %>% summarise(n = n()) %>% arrange(desc(n))
# Number of sizes of windows detected
df_final %>% group_by(seq) %>% summarise(n = n()) %>% arrange(desc(n))
# Average recall and precision by variable
df_final %>% group_by(variable) %>% summarise(mean_recall = mean(recall), mean_precision = mean(precision)) %>% arrange(desc(mean_precision))
# Average recall and precision by size
df_final %>% group_by(seq) %>% summarise(mean_recall = mean(recall), mean_precision = mean(precision)) %>% arrange(desc(mean_precision))
